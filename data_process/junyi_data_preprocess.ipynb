{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EduData import get_data\n",
    "import os\n",
    "data_path = './'\n",
    "file_name = data_path + 'junyi_ProblemLog_original.csv'\n",
    "# Please refer to this link for Junyi dataset: https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=1198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "data = pd.read_csv(\n",
    "    file_name\n",
    ")\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=[\"problem_type\",\"exercise\",\"time_taken_attempts\"])\n",
    "student_counts = data['user_id'].value_counts()\n",
    "# find 1000 most active students\n",
    "top_1000_students = student_counts.nlargest(1000).index\n",
    "filtered_df = data[data['user_id'].isin(top_1000_students)]\n",
    "# filter questions answered less than 10 times\n",
    "question_counts = filtered_df['exercise'].value_counts()\n",
    "less_10_answered = question_counts[question_counts < 10].index\n",
    "filtered_df = filtered_df[~filtered_df['exercise'].isin(less_10_answered)]\n",
    "filtered_df.sort_values(by = 'time_done', inplace = True)\n",
    "filtered_df['time_first_res'] = filtered_df['time_taken_attempts'].str.split('&').str[0].astype(int)\n",
    "filtered_df = filtered_df[filtered_df[\"time_first_res\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_relation = pd.read_csv(data_path + \"junyi_Exercise_table.csv\")\n",
    "\n",
    "problems = filtered_df.exercise.unique().tolist()\n",
    "exercise_topic_relation = exercise_relation[exercise_relation[\"name\"].isin(problems)]\n",
    "skills = exercise_topic_relation[\"topic\"].unique().tolist()\n",
    "users = filtered_df.user_id.unique()\n",
    "\n",
    "# question id from 1 to #num_skill\n",
    "skill2id = { p: i+1 for i, p in enumerate(skills) }\n",
    "problem2id = { p: i+1 for i, p in enumerate(problems) }\n",
    "\n",
    "\n",
    "print(\"number of users: %d\" % len(users))\n",
    "print(\"number of skills: %d\" % len(skills))\n",
    "print(\"number of problems: %d\" % len(problems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "problem2skill = {}\n",
    "for p,s in zip(np.array(exercise_topic_relation.name), np.array(exercise_topic_relation.topic)):\n",
    "    problem2skill[problem2id[p]] = skill2id[s]\n",
    "with open(data_path + 'problem2skill', 'w', encoding='utf-8') as f:\n",
    "    f.write(str(problem2skill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import poisson\n",
    "\n",
    "train_student_ids, test_student_ids = train_test_split(users, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = filtered_df[filtered_df['user_id'].isin(train_student_ids)]\n",
    "\n",
    "\n",
    "# compute the mean and variance of the response time for each question\n",
    "question_time_stats = train_data.groupby('exercise')['time_first_res'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# merge the time statistics to the original data\n",
    "filtered_df = pd.merge(filtered_df, question_time_stats, on='exercise')\n",
    "filtered_df['std'] = filtered_df['std'].fillna(0)\n",
    "print(\"finish merging\")\n",
    "\n",
    "# compute the time factor with its distribution\n",
    "filtered_df['time_factor'] = filtered_df.apply(lambda row: 1 if row['std'] == 0 else norm(row['mean'], row['std']).cdf(np.log(row['time_first_res'])), axis=1)\n",
    "filtered_df = filtered_df.dropna(subset = ['time_factor'])\n",
    "print(\"Finish processing time features \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean of the attempts\n",
    "question_attempt_stats = train_data.groupby('exercise')['count_attempts'].mean().reset_index()\n",
    "question_attempt_stats.rename(columns = {'count_attempts':'mean_attempt'}, inplace = True)\n",
    "# merge the attempts statistics to the original data\n",
    "filtered_df = pd.merge(filtered_df, question_attempt_stats, on='exercise', suffixes=('', '_attempt'))\n",
    "\n",
    "# compute the attempt factor with its distribution\n",
    "filtered_df['attempt_factor'] = 1 - poisson(filtered_df['mean_attempt']).cdf(filtered_df['count_attempts'] - 1)\n",
    "print(\"Finish processing attempt features \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean of the hints\n",
    "question_hint_stats = train_data.groupby('exercise')['count_hints'].agg('mean').reset_index()\n",
    "question_hint_stats.rename(columns = {'count_hints':'mean_hint'}, inplace = True)\n",
    "# merge the hints statistics to the original data\n",
    "filtered_df = pd.merge(filtered_df, question_hint_stats, on='exercise', suffixes=('', '_hint'))\n",
    "\n",
    "# compute the hint factor with its distribution\n",
    "filtered_df['hint_factor'] = 1 - poisson(filtered_df['mean_hint']).cdf(filtered_df['count_hints'] - 1)\n",
    "\n",
    "print(\"Finish processing hint features \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_all_seq(students):\n",
    "    all_sequences = []\n",
    "    for student_id in tqdm.tqdm(students, 'parse student sequence:\\t'):\n",
    "        student_sequence = parse_student_seq(filtered_df[filtered_df.user_id == student_id])\n",
    "        all_sequences.extend([student_sequence])\n",
    "    print(all_sequences)\n",
    "    return all_sequences\n",
    "\n",
    "\n",
    "def parse_student_seq(student):\n",
    "    seq = student\n",
    "    s = [problem2skill[problem2id[p]] for p in seq.exercise.tolist()]\n",
    "    a = seq.correct.tolist()\n",
    "    p = [problem2id[p] for p in seq.exercise.tolist()]\n",
    "    time_factor = seq.time_factor.tolist()\n",
    "    attempt_factor = seq.attempt_factor.tolist()\n",
    "    hint_factor = seq.hint_factor.tolist()\n",
    "\n",
    "    return s, a, p, time_factor,attempt_factor,hint_factor\n",
    "\n",
    "\n",
    "train_data = np.array(parse_all_seq(train_student_ids))\n",
    "test_data = np.array(parse_all_seq(test_student_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequences2l(sequences, trg_path):\n",
    "    with open(trg_path, 'w', encoding='utf8') as f:\n",
    "        for seq in tqdm.tqdm(sequences, 'write data into file: %s' % trg_path):\n",
    "            s_seq, a_seq, p_seq, time_seq, attempt_seq, hint_seq = seq\n",
    "            seq_len = len(s_seq)\n",
    "            f.write(str(seq_len) + '\\n')\n",
    "            f.write(','.join([str(s) for s in s_seq]) + '\\n')\n",
    "            f.write(','.join([str(a) for a in a_seq]) + '\\n')\n",
    "            f.write(','.join([str(p) for p in p_seq]) + '\\n')\n",
    "            f.write(','.join([format(t, '.6f') for t in time_seq]) + '\\n')\n",
    "            f.write(','.join([format(att, '.6f') for att in attempt_seq]) + '\\n')\n",
    "            f.write(','.join([format(h, '.6f') for h in hint_seq]) + '\\n')\n",
    "\n",
    "sequences2l(train_data, data_path + 'train.txt')\n",
    "sequences2l(test_data, data_path + 'test.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "3b66e6dcbde988b5add865525f28c8356d90c16d853dfc33b69f8106a51fbf66"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
